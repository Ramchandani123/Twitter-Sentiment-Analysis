{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb5b019",
   "metadata": {},
   "source": [
    "INSTALL THE NECESSARY LIBRARIES\n",
    "\n",
    "This block install and imports the required libraries , it uses pandas to load and handle data , TfidVectorizer to turn text into numbers and scikit learn to train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb4dd839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0e86de",
   "metadata": {},
   "source": [
    "LOAD DATASET\n",
    "\n",
    "- Here we loads the Sentiment140 dataset from a zipped CSV file, we can also download this file from kaggle also \n",
    "\n",
    "-  we keep onle the polarity and tweet text columns, renames them for clarity and prints the first few rows to chexk the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5031074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\ohk\\training.1600000.processed.noemoticon.csv\",encoding =\"latin-1\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e94f973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    polarity                                               text\n",
      "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1          0  is upset that he can't update his Facebook by ...\n",
      "2          0  @Kenichan I dived many times for the ball. Man...\n",
      "3          0    my whole body feels itchy and like its on fire \n",
      "4          0  @nationwideclass no, it's not behaving at all....\n",
      "..       ...                                                ...\n",
      "95         0  Strider is a sick little puppy  http://apps.fa...\n",
      "96         0  so rylee,grace...wana go steve's party or not?...\n",
      "97         0  hey, I actually won one of my bracket pools! T...\n",
      "98         0  @stark YOU don't follow me, either  and i work...\n",
      "99         0  A bad nite for the favorite teams: Astros and ...\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = data[[0,5]]\n",
    "data.columns = [\"polarity\",\"text\"]\n",
    "print(data.head(100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e44e5",
   "metadata": {},
   "source": [
    "KEEP ONLY POSITIVE AND NEGATIVE SENTIMENTS \n",
    "\n",
    "- Here we remove neutral tweets where the polarity is 2,maps the labels so 0 stays negative and 4 becomes 1 for positive \n",
    "\n",
    "- Then er print how many positive and negative tweets are left in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d68948cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity\n",
      "0    800000\n",
      "1    800000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = data[data.polarity != 2]\n",
    "\n",
    "data[\"polarity\"] = data[\"polarity\"].map({0:0,4:1})\n",
    "print(data[\"polarity\"].value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d2a448",
   "metadata": {},
   "source": [
    "CLEAN THE TWEETS \n",
    "\n",
    "- Here we define a simple function to convert all text to loowercase  for consistency, applies it to every tweet in the dataset\n",
    "\n",
    "- then shows the original and cleaned version of the first few tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9ccf3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
      "1  is upset that he can't update his Facebook by ...   \n",
      "2  @Kenichan I dived many times for the ball. Man...   \n",
      "3    my whole body feels itchy and like its on fire    \n",
      "4  @nationwideclass no, it's not behaving at all....   \n",
      "\n",
      "                                          clean_text  \n",
      "0  @switchfoot http://twitpic.com/2y1zl - awww, t...  \n",
      "1  is upset that he can't update his facebook by ...  \n",
      "2  @kenichan i dived many times for the ball. man...  \n",
      "3    my whole body feels itchy and like its on fire   \n",
      "4  @nationwideclass no, it's not behaving at all....  \n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    return text.lower()\n",
    "data[\"clean_text\"] = data[\"text\"].apply(clean_text)\n",
    "print(data[[\"text\",\"clean_text\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88885c1",
   "metadata": {},
   "source": [
    "TRAIN TEST SPLIT\n",
    "\n",
    "- This code splits the clean_text and polarity column into training and testing sets using am 80/20 split\n",
    "\n",
    "randon_state = 42 ensures reporducibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca2fafb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 1280000\n",
      "Test_size: 320000\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data[\"clean_text\"],data[\"polarity\"],random_state=42 , test_size=0.2)\n",
    " \n",
    "print(\"Train Size:\",len(x_train))\n",
    "print(\"Test_size:\",len(x_test)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ef8834",
   "metadata": {},
   "source": [
    "PERFORM VALIDATION\n",
    "\n",
    "- This code creates a TF IDF vectorizer that converts text into numerical featureusing unigrams and bigrams limited to 5000 feature \n",
    "\n",
    "- its fits and transform the training data and transform the test data and prints the shapes of resulting TF IDF metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76dad204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape (train): (1280000, 5000)\n",
      "TF-IDF shape (test): (320000, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "x_train_tfidf = vectorizer.fit_transform(x_train)\n",
    "x_test_tfidf  = vectorizer.transform(x_test)\n",
    "\n",
    "print(\"TF-IDF shape (train):\", x_train_tfidf.shape)\n",
    "print(\"TF-IDF shape (test):\", x_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14343cfd",
   "metadata": {},
   "source": [
    "TRAIN BERNOULI NAIVE BAYES MODEL\n",
    "\n",
    "- Here we train a Bernouli Naive Bayes Classifier on TF IDF features  from the training data \n",
    "\n",
    "- it predicts sentiments for the test data and then prints the accuracy and a detailed classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6636400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernouli Naive Bayes Accuracy: 0.766478125\n",
      "/nBernoulib classification report:/n               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76    159494\n",
      "           1       0.76      0.78      0.77    160506\n",
      "\n",
      "    accuracy                           0.77    320000\n",
      "   macro avg       0.77      0.77      0.77    320000\n",
      "weighted avg       0.77      0.77      0.77    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(x_train_tfidf,y_train)\n",
    "bnb_pred = bnb.predict(x_test_tfidf)\n",
    "print(\"Bernouli Naive Bayes Accuracy:\",accuracy_score(y_test,bnb_pred))\n",
    "print(\"/nBernoulib classification report:/n\",classification_report(y_test,bnb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfd67c8",
   "metadata": {},
   "source": [
    "TRAIN SUPPORT VECTOR MACHINE (SVM) MODEL\n",
    "\n",
    "- This code trains a support vector machine witha maximum of 1000 iterating on the TF IDF festure \n",
    "\n",
    "- it predicts text label than points the accuracy and a detailed classification report showing how well the SVM performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a093ea52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.79528125\n",
      "\n",
      "Classifier Report:/n               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79    154168\n",
      "           1       0.81      0.79      0.80    165832\n",
      "\n",
      "    accuracy                           0.80    320000\n",
      "   macro avg       0.80      0.80      0.80    320000\n",
      "weighted avg       0.80      0.80      0.80    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(max_iter=1000)\n",
    "svm.fit(x_train_tfidf,y_train)\n",
    "svm_pred = svm.predict(x_test_tfidf)\n",
    "print(\"SVM Accuracy:\",accuracy_score(svm_pred,y_test))\n",
    "print(\"\\nClassifier Report:/n\" , classification_report(svm_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f54b1",
   "metadata": {},
   "source": [
    "TRAIN LOGISTIC REGRESSION MODEL\n",
    "- This code trins a logistic regression model with up to 100 iterations on the TF IDF features\n",
    "\n",
    "- it predicts sentiment labels for the test data and prints the accuracy and detailed classifiaction report for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ab72b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.79539375\n",
      "\n",
      " Classification Report:/n               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79    155344\n",
      "           1       0.81      0.79      0.80    164656\n",
      "\n",
      "    accuracy                           0.80    320000\n",
      "   macro avg       0.80      0.80      0.80    320000\n",
      "weighted avg       0.80      0.80      0.80    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logpreg =  LogisticRegression(max_iter=100) \n",
    "logpreg.fit(x_train_tfidf,y_train)\n",
    "\n",
    "logpreg_pred = logpreg.predict(x_test_tfidf)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\",accuracy_score(logpreg_pred,y_test))\n",
    "print(\"\\n Classification Report:/n\",classification_report(logpreg_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8936ec9e",
   "metadata": {},
   "source": [
    "MAKE PREDICTION ON SAMPLE TWEETS \n",
    "\n",
    "- this code take three sample tweets and tranform them into TF IDF feature using the same vectorizer \n",
    "\n",
    "- It then predicts their sentiment using the trained BernouliNB , SVM,LogisticRegression and prints the result for each classfier \n",
    "\n",
    "- where 1 stands for positive and 0 for negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cb8a9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions:\n",
      "BernoulliNB: [1 0 1]\n",
      "SVM: [1 0 1]\n",
      "Logistic Regression: [1 0 1]\n"
     ]
    }
   ],
   "source": [
    "sample_tweets = [\"I love this!\", \"I hate that!\", \"It was okay, not great.\"]\n",
    "sample_vec = vectorizer.transform(sample_tweets)\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "print(\"BernoulliNB:\", bnb.predict(sample_vec))\n",
    "print(\"SVM:\", svm.predict(sample_vec))\n",
    "print(\"Logistic Regression:\", logpreg.predict(sample_vec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
